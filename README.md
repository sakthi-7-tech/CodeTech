## ğŸš€ CodTech Internship 
## ğŸ“‚ Project Structure
# Task 1: Big Data Analysis

## ğŸ“Œ Objective
Perform big data analysis on a large dataset using tools such as *PySpark* or *Dask, with a focus on demonstrating **scalability* and deriving meaningful insights from large-scale data processing.

---

## ğŸ›  Tools & Technologies Used
- Python
- PySpark / Dask (choose based on your implementation)
- Jupyter Notebook / Python Script
- Pandas (for pre-processing, if needed)
- Matplotlib / Seaborn (optional for visualization)

---

# Task 2: Predictive Analysis Using Machine Learning

## Dataset Used
Titanic Survival Dataset from Kaggle: https://www.kaggle.com/c/titanic/data

## Objective
To build a logistic regression model that predicts passenger survival based on features like Age, Gender, Pclass, etc.

## Steps Performed
- Data cleaning & preprocessing
- Feature encoding
- Logistic Regression model training
- Evaluation using accuracy score, confusion matrix, and classification report

## Model Accuracy
Achieved accuracy: **~80%** (may vary)

## Tools Used
- Python
- Pandas, Scikit-learn
- Matplotlib, Seaborn

## Deliverables
- `predictive_analysis.ipynb`
- `README.md`

# ğŸ“Š CodTech Internship â€“ Task 3: Dashboard Development

## ğŸ“ Objective
To develop an interactive and insightful dashboard using *Power BI*, enabling visual exploration and actionable insights from the dataset.

---

## ğŸš€ Tools & Technologies
- ğŸŸ¡ Power BI Desktop
- ğŸ“ Excel/CSV Dataset
- ğŸ“Š Charts, Filters, Slicers
- (Optional) DAX formulas

---

## ğŸ“‚ Project Structure

# Task 4 - Sentiment Analysis using NLP ğŸ’¬

This project is part of my internship at *CodTech. The goal is to perform sentiment analysis on Twitter data using Natural Language Processing (NLP) techniques. We classify each tweet as either **positive* or *negative* based on its content.

---

## ğŸ” Project Objective

- Clean and preprocess real-world tweet data
- Convert text into numerical format using TF-IDF
- Train a machine learning model (Logistic Regression)
- Evaluate the model's performance
- Visualize positive sentiment words using a Word Cloud

---

## ğŸ“ Dataset Used

- *File:* tweet.csv
- *Format:* CSV with 6 columns (no headers)
- *Content:* Sentiment140-style tweet data  
  Columns: Sentiment, ID, Date, Query, User, Text

---

## ğŸ›  Technologies Used

- Python ğŸ
- Pandas
- NumPy
- NLTK (Natural Language Toolkit)
- Scikit-learn
- Matplotlib & Seaborn
- WordCloud

---

## ğŸ§  Steps Performed

1. *Data Loading*  
   Loaded tweet dataset using ISO-8859-1 encoding.

2. *Column Setup*  
   Manually assigned column names:
